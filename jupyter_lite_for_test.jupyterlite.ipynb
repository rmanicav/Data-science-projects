{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "def6c2b16be03b8590d636aa576bdaff4206d1ae9e8a5ace4be932c0f896e5bb"
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment for Generative AI classroom labs\n\nThis lab provides a test environment for the codes generated using the Generative AI classroom.\n\nFollow the instructions below to set up this environment for further use.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Setup\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Install required libraries\n\nIn case of a requirement of installing certain python libraries for use in your task, you may do so as shown below.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%pip install seaborn\nimport piplite\n\nawait piplite.install(['nbformat', 'plotly'])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Dataset URL from the GenAI lab\nUse the URL provided in the GenAI lab in the cell below. \n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0271EN-SkillsNetwork/labs/v1/m3/data/used_car_price_analysis.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "### Downloading the dataset\n\nExecute the following code to download the dataset in to the interface.\n\n> Please note that this step is essential in JupyterLite. If you are using a downloaded version of this notebook and running it on JupyterLabs, then you can skip this step and directly use the URL in pandas.read_csv() function to read the dataset as a dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())\n\npath = URL\n\nawait download(path, \"dataset.csv\")\nfile_name  = \"dataset.csv\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": "---\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Test Environment\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Keep appending the code generated to this cell, or add more cells below this to execute in parts\n# Install dependencies as needed:\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\n\n# Read data from CSV into a DataFrame\n# Replace 'data.csv' with your actual file path\ndf = pd.read_csv('dataset.csv')\n\n# Remove duplicate rows\ndf = df.drop_duplicates()\n\n# Fill missing values\n# Numeric columns: fill with the column mean\nnumeric_cols = df.select_dtypes(include=['number']).columns\nfor col in numeric_cols:\n    df[col] = df[col].fillna(df[col].mean())\n\n# Categorical/object columns: fill with the most frequent value (mode)\nobject_cols = df.select_dtypes(include=['object']).columns\nfor col in object_cols:\n    df[col] = df[col].fillna(df[col].mode().iloc[0])\n\n# Output the cleaned DataFrame (optional)\nprint(df)\n\n # Determine the fuel type column using common names\nfuel_col = None\nfor candidate in ['fuel_type', 'fuel', 'fueltype', 'fuel_type_desc']:\n        if candidate in df.columns:\n            fuel_col = candidate\n            break\n\n # Fallback: find any column that contains the substring 'fuel'\nif fuel_col is None:\n       for col in df.columns:\n           if 'fuel' in col.lower():\n                fuel_col = col\n                break\n\n    # Count the number of sales per fuel type\nsales_per_fuel = df[fuel_col].value_counts().reset_index()\nsales_per_fuel.columns = ['fuel_type', 'sales_count']\nprint(sales_per_fuel)\n\n# Detect price column from common names, otherwise pick the first column\nprice_col = None\nfor cand in ['price', 'price_usd', 'price_currency', 'price_amount']:\n       if cand in df.columns:\n            price_col = cand\n            break\nif price_col is None:\n       price_col = df.columns[0]\n\npath = 'dataset.csv'  # e.g., 'housing.csv'\ncompare_results = compare_models_on_dataset(\nfile_path=path,\ntarget_col='target',  # change to your actual target column\ndegree=2,\ntest_size=0.2,\nrandom_state=42\n)\n    # Optionally inspect raw results in the console\nprint(\"\\nSummary:\")\nfor r in compare_results:\n      print(r)\n\n\ndef compare_models_on_dataset(\n    file_path: str,\n    target_col: str = 'target',\n    degree: int = 2,\n    test_size: float = 0.2,\n    random_state: int = 42\n) -> list:\n    \"\"\"Compare Linear, Polynomial, and Ridge regression models.\n\n    - Evaluates models on a single feature (the first numeric feature) and\n      on multiple features (all numeric features).\n    - Returns a list of result dictionaries with RMSE and R^2 for each model.\n    \n    Parameters:\n      file_path (str): Path to a CSV file containing the dataset.\n      target_col (str): Name of the numeric target column to predict.\n      degree (int): Degree for the polynomial features.\n      test_size (float): Proportion of data to use as the test set.\n      random_state (int): Seed for reproducibility.\n    \"\"\"\n\n    # Load data from CSV\n    df = pd.read_csv(file_path)\n\n    # Identify numeric feature columns, excluding the target column\n    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n    if target_col in numeric_cols:\n        numeric_cols.remove(target_col)\n\n    # If no numeric features, nothing to compare\n    if not numeric_cols:\n        print(\"No numeric feature columns found for modeling.\")\n        return []\n\n    # Separate features and target\n    X_all = df[numeric_cols]\n    y = df[target_col]\n\n    # Split data into training and testing sets (same split for all experiments)\n    X_train_all, X_test_all, y_train, y_test = train_test_split(\n        X_all, y, test_size=test_size, random_state=random_state\n    )\n\n    results = []  # collect results for all configurations\n\n    # Evaluate two feature settings: single feature vs all features\n    for mode, feature_cols in [('single', [numeric_cols[0]]), ('multiple', numeric_cols)]:\n        X_train = X_train_all[feature_cols]\n        X_test = X_test_all[feature_cols]\n\n        # Define three model families\n        models = {\n            'LinearRegression': LinearRegression(),\n            'PolynomialDegree{}__SingleOrAll'.format(degree): Pipeline([\n                ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n                ('linear', LinearRegression())\n            ]),\n            'Ridge': Ridge(alpha=1.0)\n        }\n\n        for model_name, model in models.items():\n            # Fit model on training data\n            model.fit(X_train, y_train)\n\n            # Predict on test data\n            y_pred = model.predict(X_test)\n\n            # Evaluate performance\n            rmse = mean_squared_error(y_test, y_pred, squared=False)\n            r2 = r2_score(y_test, y_pred)\n\n            results.append({\n                'mode': mode,\n                'feature_set': 'single' if mode == 'single' else 'multiple',\n                'model': model_name,\n                'rmse': rmse,\n                'r2': r2\n            })\n\n    # Print a compact summary\n    for r in results:\n        print(\n            \"Mode: {mode}, Feature set: {feat}, Model: {m}, RMSE: {rmse:.4f}, R2: {r2:.4f}\".format(\n                mode=r['mode'], feat=r['feature_set'], m=r['model'], rmse=r['rmse'], r2=r['r2']\n            )\n        )\n\n    return results\n\n\n\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "         model  year transmission  mileage fuelType    tax   mpg  engineSize  \\\n0       Fiesta  2017    Automatic    15944   Petrol  150.0  57.7         1.0   \n1        Focus  2018       Manual     9083   Petrol  150.0  57.7         1.0   \n2        Focus  2017       Manual    12456   Petrol  150.0  57.7         1.0   \n3       Fiesta  2019       Manual    10460   Petrol  145.0  40.3         1.5   \n4       Fiesta  2019    Automatic     1482   Petrol  145.0  48.7         1.0   \n...        ...   ...          ...      ...      ...    ...   ...         ...   \n17961    B-MAX  2017       Manual    16700   Petrol  150.0  47.1         1.4   \n17962    B-MAX  2014       Manual    40700   Petrol   30.0  57.7         1.0   \n17963    Focus  2015       Manual     7010   Diesel   20.0  67.3         1.6   \n17964       KA  2018       Manual     5007   Petrol  145.0  57.7         1.2   \n17965    Focus  2015       Manual     5007   Petrol   22.0  57.7         1.0   \n\n       price  \n0      12000  \n1      14000  \n2      13000  \n3      17500  \n4      16500  \n...      ...  \n17961   8999  \n17962   7499  \n17963   9999  \n17964   8299  \n17965   8299  \n\n[17812 rows x 9 columns]\n  fuel_type  sales_count\n0    Petrol        12081\n1    Diesel         5706\n2    Hybrid           22\n3  Electric            2\n4     Other            1\n",
          "output_type": "stream"
        },
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'compare_models_on_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m        price_col \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     61\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# e.g., 'housing.csv'\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m compare_results \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_models_on_dataset\u001b[49m(\n\u001b[1;32m     63\u001b[0m file_path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m     64\u001b[0m target_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# change to your actual target column\u001b[39;00m\n\u001b[1;32m     65\u001b[0m degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     66\u001b[0m test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     67\u001b[0m random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# Optionally inspect raw results in the console\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSummary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compare_models_on_dataset' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Change Log\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n|-|-|-|-|\n|2023-12-10|0.1|Abhishek Gagneja|Initial Draft created|\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Copyright Â© 2023 IBM Corporation. All rights reserved.\n",
      "metadata": {}
    }
  ]
}